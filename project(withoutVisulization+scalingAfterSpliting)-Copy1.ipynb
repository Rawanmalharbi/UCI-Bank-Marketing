{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793a0211",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (Temp/ipykernel_52128/3532308867.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\raww9\\AppData\\Local\\Temp/ipykernel_52128/3532308867.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    pip install xgboost\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    " pip install xgboost\n",
    "## Basic libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## Data Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Bulid the data Model\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from io import StringIO\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "%matplotlib inline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score,recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set(font_scale = 1.1)\n",
    "#########\n",
    "# Configure libraries\n",
    "# changing figure size\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "221735f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table {float:left}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "    table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bc0c07",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52128/2550021495.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'bank-full.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m';'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('bank-full.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac2dd12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52128/4234678360.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'y'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'deposit'\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.rename(columns ={'y':'deposit'} , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing yes and no from deposit column by 1 and 0 to convert categorical feature to numerical feature\n",
    "df['deposit'].replace(to_replace='yes', value=1, inplace=True)\n",
    "df['deposit'].replace(to_replace='no',  value=0, inplace=True)\n",
    "df['deposit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ac8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing yes and no from loan column by 1 and 0 to convert categorical feature to numerical feature\n",
    "df['loan'].replace(to_replace='no', value=1, inplace=True)\n",
    "df['loan'].replace(to_replace='yes',  value=0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f9c6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing yes and no from default column by 1 and 0 to convert categorical feature to numerical feature\n",
    "df['default'].replace(to_replace='no', value=1, inplace=True)\n",
    "df['default'].replace(to_replace='yes',  value=0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592501d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing yes and no from housing column by 1 and 0 to convert categorical feature to numerical feature\n",
    "df['housing'].replace(to_replace='no', value=1, inplace=True)\n",
    "df['housing'].replace(to_replace='yes',  value=0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for marital feature to convert categorical feature to numerical feature\n",
    "# dropping original column\n",
    "# dropping one of the resultant columns\n",
    "\n",
    "one_hot = pd.get_dummies(df['marital'])\n",
    "df = df.drop('marital',axis = 1)\n",
    "df = df.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9bb39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('divorced',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370f4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for education feature to convert categorical feature to numerical feature\n",
    "# dropping original column\n",
    "# dropping one of the resultant columns\n",
    "\n",
    "one_hot = pd.get_dummies(df['education'])\n",
    "df = df.drop('education',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "df = df.drop('unknown',axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948da2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df['job'])\n",
    "df = df.drop('job',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "df = df.drop('unknown',axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb3f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for contact feature to convert categorical feature to numerical feature\n",
    "# dropping original column\n",
    "# dropping one of the resultant columns\n",
    "\n",
    "one_hot = pd.get_dummies(df['contact'])\n",
    "df = df.drop('contact',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "df = df.drop('unknown',axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for month feature to convert categorical feature to numerical feature\n",
    "# dropping original column\n",
    "# dropping one of the resultant columns\n",
    "\n",
    "one_hot = pd.get_dummies(df['month'])\n",
    "df = df.drop('month',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "df = df.drop('dec',axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for poutcome feature to convert categorical feature to numerical feature\n",
    "# dropping original column\n",
    "# dropping one of the resultant columns\n",
    "\n",
    "one_hot = pd.get_dummies(df['poutcome'])\n",
    "df = df.drop('poutcome',axis = 1)\n",
    "df = df.join(one_hot)\n",
    "df = df.drop('other',axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3654dd3",
   "metadata": {},
   "source": [
    "##scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e14274",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Copying original dataframe\n",
    "bank= df.copy()\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#num_cols = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
    "#bank[num_cols] = scaler.fit_transform(bank[num_cols])\n",
    "\n",
    "#bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a821fd",
   "metadata": {},
   "source": [
    "##split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Features\n",
    "feature = bank.drop('deposit', axis=1)\n",
    "\n",
    "# Select Target\n",
    "target = bank['deposit']\n",
    "\n",
    "# Set Training and Testing Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(feature,target,test_size=0.2,random_state=1)\n",
    "\n",
    "# Show the Training and Testing Data\n",
    "print('Shape of training feature:', X_train.shape)\n",
    "print('Shape of testing feature:', X_test.shape)\n",
    "print('Shape of training label:', y_train.shape)\n",
    "print('Shape of training label:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd238eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "X_train =scaler.fit_transform(X_train)\n",
    "X_test_Scaled =scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86df26de",
   "metadata": {},
   "source": [
    "##Eval method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a235ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    from sklearn import metrics\n",
    "\n",
    "    # Predict Test Data \n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "    # Calculate accuracy, precision, recall, f1-score, and kappa score\n",
    "    acc = metrics.accuracy_score(y_test, y_pred)\n",
    "    prec = metrics.precision_score(y_test, y_pred)\n",
    "    rec = metrics.recall_score(y_test, y_pred)\n",
    "    f1 = metrics.f1_score(y_test, y_pred)\n",
    "\n",
    "    # Calculate area under curve (AUC)\n",
    "    y_pred_proba = model.predict_proba(x_test)[::,1]\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "    # Display confussion matrix\n",
    "    cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    return {'acc': acc, 'prec': prec, 'rec': rec, 'f1': f1,'fpr': fpr, 'tpr': tpr, 'auc': auc, 'cm': cm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539918a",
   "metadata": {},
   "source": [
    "##DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d180f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Building Decision Tree model \n",
    "dtc = tree.DecisionTreeClassifier(criterion = 'entropy',random_state=0)\n",
    "dtc.fit(X_train, y_train)\n",
    "# Evaluate Model\n",
    "dtc_eval = evaluate_model(dtc, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', dtc_eval['acc'])\n",
    "print('Precision:', dtc_eval['prec'])\n",
    "print('Recall:', dtc_eval['rec'])\n",
    "print('F1 Score:', dtc_eval['f1'])\n",
    "print('Area Under Curve:', dtc_eval['auc'])\n",
    "print('Confusion Matrix:\\n', dtc_eval['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b79c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e33105",
   "metadata": {},
   "source": [
    "##RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a277264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Building Random Forest model \n",
    "rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy',random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "# Evaluate Model\n",
    "rf_eval = evaluate_model(rf, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', rf_eval['acc'])\n",
    "print('Precision:', rf_eval['prec'])\n",
    "print('Recall:', rf_eval['rec'])\n",
    "print('F1 Score:', rf_eval['f1'])\n",
    "print('Area Under Curve:', rf_eval['auc'])\n",
    "print('Confusion Matrix:\\n', rf_eval['cm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db376281",
   "metadata": {},
   "source": [
    "##NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad41f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Building Naive Bayes model \n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "# Evaluate Model\n",
    "nb_eval = evaluate_model(nb, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', nb_eval['acc'])\n",
    "print('Precision:', nb_eval['prec'])\n",
    "print('Recall:', nb_eval['rec'])\n",
    "print('F1 Score:', nb_eval['f1'])\n",
    "print('Area Under Curve:', nb_eval['auc'])\n",
    "print('Confusion Matrix:\\n', nb_eval['cm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de635347",
   "metadata": {},
   "source": [
    "##KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cc5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Building KNN model \n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "# Evaluate Model\n",
    "knn_eval = evaluate_model(knn, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "print('Accuracy:', knn_eval['acc'])\n",
    "print('Precision:', knn_eval['prec'])\n",
    "print('Recall:', knn_eval['rec'])\n",
    "print('F1 Score:', knn_eval['f1'])\n",
    "print('Area Under Curve:', knn_eval['auc'])\n",
    "print('Confusion Matrix:\\n', knn_eval['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19df2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##svc\n",
    "#from sklearn.svm import SVC\n",
    "#svc = SVC(kernel = 'linear', random_state = 0)\n",
    "#svc.fit(X_train, y_train)\n",
    "# Evaluate Model\n",
    "#SVC_eval = evaluate_model(svc, X_test, y_test)\n",
    "\n",
    "# Print result\n",
    "#print('Accuracy:', knn_eval['acc'])\n",
    "#print('Precision:', knn_eval['prec'])\n",
    "#print('Recall:', knn_eval['rec'])\n",
    "#print('F1 Score:', knn_eval['f1'])\n",
    "#print('Area Under Curve:', knn_eval['auc'])\n",
    "#print('Confusion Matrix:\\n', knn_eval['cm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa442d35",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_52128/950881305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Intitialize figure with two plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0max1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model Comparison'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bold'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figheight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_figwidth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Intitialize figure with two plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Model Comparison', fontsize=16, fontweight='bold')\n",
    "fig.set_figheight(7)\n",
    "fig.set_figwidth(14)\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "# First plot\n",
    "## set bar size\n",
    "barWidth = 0.2\n",
    "dtc_score = [dtc_eval['acc'], dtc_eval['prec'], dtc_eval['rec'], dtc_eval['f1']]\n",
    "rf_score = [rf_eval['acc'], rf_eval['prec'], rf_eval['rec'], rf_eval['f1']]\n",
    "nb_score = [nb_eval['acc'], nb_eval['prec'], nb_eval['rec'], nb_eval['f1']]\n",
    "knn_score = [knn_eval['acc'], knn_eval['prec'], knn_eval['rec'], knn_eval['f1']]\n",
    "\n",
    "## Set position of bar on X axis\n",
    "r1 = np.arange(len(dtc_score))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "\n",
    "## Make the plot\n",
    "ax1.bar(r1, dtc_score, width=barWidth, edgecolor='white', label='Decision Tree')\n",
    "ax1.bar(r2, rf_score, width=barWidth, edgecolor='white', label='Random Forest')\n",
    "ax1.bar(r3, nb_score, width=barWidth, edgecolor='white', label='Naive Bayes')\n",
    "ax1.bar(r4, knn_score, width=barWidth, edgecolor='white', label='K-Nearest Neighbors')\n",
    "\n",
    "## Configure x and y axis\n",
    "ax1.set_xlabel('Metrics', fontweight='bold')\n",
    "labels = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "ax1.set_xticks([r + (barWidth * 1.5) for r in range(len(dtc_score))], )\n",
    "ax1.set_xticklabels(labels)\n",
    "ax1.set_ylabel('Score', fontweight='bold')\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "## Create legend & title\n",
    "ax1.set_title('Evaluation Metrics', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# Second plot\n",
    "## Comparing ROC Curve\n",
    "ax2.plot(dtc_eval['fpr'], dtc_eval['tpr'], label='Decision Tree, auc = {:0.5f}'.format(dtc_eval['auc']))\n",
    "ax2.plot(rf_eval['fpr'], rf_eval['tpr'], label='Random Forest, auc = {:0.5f}'.format(rf_eval['auc']))\n",
    "ax2.plot(nb_eval['fpr'], nb_eval['tpr'], label='Naive Bayes, auc = {:0.5f}'.format(nb_eval['auc']))\n",
    "ax2.plot(knn_eval['fpr'], knn_eval['tpr'], label='K-Nearest Nieghbor, auc = {:0.5f}'.format(knn_eval['auc']))\n",
    "\n",
    "## Configure x and y axis\n",
    "ax2.set_xlabel('False Positive Rate', fontweight='bold')\n",
    "ax2.set_ylabel('True Positive Rate', fontweight='bold')\n",
    "\n",
    "## Create legend & title\n",
    "ax2.set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9d51e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de623764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc81e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
